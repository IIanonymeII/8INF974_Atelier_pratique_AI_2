{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9100\\2699802428.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/foot_for_nba_prepro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"AwayTeam\",\"HomeTeam\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away_team_form</th>\n",
       "      <th>away_win_percentage</th>\n",
       "      <th>away_win</th>\n",
       "      <th>away_lose</th>\n",
       "      <th>Roadwon</th>\n",
       "      <th>Roadlost</th>\n",
       "      <th>home_team_form</th>\n",
       "      <th>home_win_percentage</th>\n",
       "      <th>home_win</th>\n",
       "      <th>home_lose</th>\n",
       "      <th>Homewon</th>\n",
       "      <th>Homelost</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   away_team_form  away_win_percentage  away_win  away_lose  Roadwon  \\\n",
       "0             4.0             0.857143       5.0        1.0      0.0   \n",
       "1             0.0             0.000000       0.0        5.0      1.0   \n",
       "2             4.0             0.555556       4.0        4.0      0.0   \n",
       "3             1.0             0.125000       1.0        6.0      1.0   \n",
       "4             0.0             0.142857       0.0        6.0      1.0   \n",
       "\n",
       "   Roadlost  home_team_form  home_win_percentage  home_win  home_lose  \\\n",
       "0       1.0             4.0             0.666667       4.0        1.0   \n",
       "1       0.0             2.0             0.500000       2.0        3.0   \n",
       "2       2.0             1.0             0.142857       1.0        5.0   \n",
       "3       1.0             5.0             0.900000       8.0        1.0   \n",
       "4       1.0             1.0             0.333333       3.0        5.0   \n",
       "\n",
       "   Homewon  Homelost  result  \n",
       "0      1.0       0.0       0  \n",
       "1      0.0       1.0       1  \n",
       "2      0.0       2.0       0  \n",
       "3      1.0       1.0       1  \n",
       "4      0.0       1.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3536 entries, 0 to 3535\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   away_team_form       3536 non-null   float64\n",
      " 1   away_win_percentage  3536 non-null   float64\n",
      " 2   away_win             3536 non-null   float64\n",
      " 3   away_lose            3536 non-null   float64\n",
      " 4   Roadwon              3536 non-null   float64\n",
      " 5   Roadlost             3536 non-null   float64\n",
      " 6   home_team_form       3536 non-null   float64\n",
      " 7   home_win_percentage  3536 non-null   float64\n",
      " 8   home_win             3536 non-null   float64\n",
      " 9   home_lose            3536 non-null   float64\n",
      " 10  Homewon              3536 non-null   float64\n",
      " 11  Homelost             3536 non-null   float64\n",
      " 12  result               3536 non-null   int64  \n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 359.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"result\"]\n",
    "X = df.drop([\"result\"], axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "scaled_X_train = pd.DataFrame(data=scaled_X_train, columns=X_train.columns)\n",
    "scaled_X_test = pd.DataFrame(data=scaled_X_test, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the decision tree classifier\n",
    "\n",
    "# dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'splitter': ['best', 'random'],\n",
    "#     'max_depth': [None, 5, 10, 15, 20],\n",
    "#     'min_samples_split': [2, 5, 10, 15],\n",
    "#     'min_samples_leaf': [1, 2, 4, 8],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#     'class_weight': [None, 'balanced'],\n",
    "#     'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3]\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(scaled_X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "best_params =  {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Test Accuracy: 0.6652542372881356\n",
      "Test f1 score: 0.7328072153325819\n",
      "Test roc auc : 0.6524673699266941\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best parameters\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(scaled_X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = best_dt_classifier.predict(scaled_X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_pred,y_test)\n",
    "test_f1 = f1_score(y_pred, y_test)\n",
    "test_auc = roc_auc_score(y_pred,y_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Score:\", best_score)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test f1 score:\", test_f1)\n",
    "print(\"Test roc auc :\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k nearest neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-Nearest Neighbors classifier\n",
    "\n",
    "# knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors to consider\n",
    "#     'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "#     'leaf_size': [10, 20, 30, 40],  # Leaf size passed to BallTree or KDTree\n",
    "#     # 'p': [1, 2, 3],  # Power parameter for the Minkowski metric\n",
    "#     # 'metric': ['euclidean', 'manhattan', 'chebyshev']  # Distance metric to use for the tree\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=knn_classifier, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(scaled_X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "best_params = {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 11, 'weights': 'uniform'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "Test Accuracy: 0.6779661016949152\n",
      "Test f1 score: 0.752711496746204\n",
      "Test roc auc : 0.6711505633321952\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best parameters\n",
    "best_knn_classifier = KNeighborsClassifier(**best_params)\n",
    "best_knn_classifier.fit(scaled_X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = best_knn_classifier.predict(scaled_X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_pred,y_test)\n",
    "test_f1 = f1_score(y_pred, y_test)\n",
    "test_auc = roc_auc_score(y_pred,y_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Score:\", best_score)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test f1 score:\", test_f1)\n",
    "print(\"Test roc auc :\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Gaussian Naive Bayes classifier\n",
    "\n",
    "# nb_classifier = GaussianNB()\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5],\n",
    "#     'priors': [None, [0.5, 0.5], [0.3, 0.7], [0.7, 0.3]]  # Prior probabilities for each class\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(scaled_X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "best_params = {'priors': None, 'var_smoothing': 1e-09}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'priors': None, 'var_smoothing': 1e-09}\n",
      "Test Accuracy: 0.6807909604519774\n",
      "Test f1 score: 0.7454954954954953\n",
      "Test roc auc : 0.6699454433067269\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best parameters\n",
    "best_nb_classifier = GaussianNB(**best_params)\n",
    "best_nb_classifier.fit(scaled_X_train, y_train)\n",
    "\n",
    "y_pred = best_nb_classifier.predict(scaled_X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_pred,y_test)\n",
    "test_f1 = f1_score(y_pred, y_test)\n",
    "test_auc = roc_auc_score(y_pred,y_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Score:\", best_score)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test f1 score:\", test_f1)\n",
    "print(\"Test roc auc :\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Support Vector Machine classifier\n",
    "\n",
    "# svm_classifier = SVC()\n",
    "\n",
    "# # Define the grid search parameters\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     # 'degree': [2, 3, 4],  # Only for polynomial kernel\n",
    "#     # 'gamma': ['scale', 'auto', 0.1, 1, 10]  # 'scale' and 'auto' are default, adding more values for gamma\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(scaled_X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "best_params = {'C': 10, 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'kernel': 'poly'}\n",
      "Test Accuracy: 0.7019774011299436\n",
      "Test f1 score: 0.7767195767195767\n",
      "Test roc auc : 0.7086489898989898\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_svm_classifier = SVC(**best_params)\n",
    "best_svm_classifier.fit(scaled_X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "\n",
    "y_pred = best_svm_classifier.predict(scaled_X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_pred,y_test)\n",
    "test_f1 = f1_score(y_pred, y_test)\n",
    "test_auc = roc_auc_score(y_pred,y_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Score:\", best_score)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test f1 score:\", test_f1)\n",
    "print(\"Test roc auc :\", test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
