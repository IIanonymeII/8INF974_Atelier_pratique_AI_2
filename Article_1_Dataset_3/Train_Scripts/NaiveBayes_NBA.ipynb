{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from TrainTestSplit_NBA import trainTestSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "'------------------------------------------------- Initial Setup -------------------------------------------------'\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.set_printoptions(precision = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IF SET B REMOVE STREAK\n",
    "XTrain, XTest, YTrain, YTest = trainTestSplit(\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21053, 10)\n",
      "(21053, 1)\n",
      "Cross Validation Score :  0.8339440530731108\n",
      "Training Accuracy :  0.8347503918681423\n",
      "Testing Accuracy :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "## Setting the classifier to be Gaussian Naive Bayes .\n",
    "Classifier = GaussianNB()\n",
    "\n",
    "## Defining a list to store the Cross-Validation Scores .\n",
    "crossValidationScores = []\n",
    "\n",
    "## Computing the 10-fold cross-validation score.\n",
    "print(XTrain.shape)\n",
    "print(YTrain.shape)\n",
    "cvScore = cross_val_score(Classifier, XTrain, YTrain['HOME_TEAM_WINS'], cv = 10)\n",
    "crossValidationScores.append(np.mean(cvScore))\n",
    "print (\"Cross Validation Score : \", np.mean(crossValidationScores))\n",
    "\n",
    "## Computing the Training and Testing Accuracies .\n",
    "Classifier.fit(XTrain,YTrain)\n",
    "print (\"Training Accuracy : \", Classifier.score(XTrain, YTrain))\n",
    "print (\"Testing Accuracy : \", Classifier.score(XTest, YTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score :  0.8339440530731108\n",
      "Training Accuracy :  0.8347503918681423\n",
      "Testing Accuracy :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "## Removing the highly correlated variables.\n",
    "#highCorr = ['Streak']\n",
    "\n",
    "#XTrain.drop(highCorr, axis = 1 , inplace = True)\n",
    "#XTest.drop(highCorr, axis = 1 , inplace = True)\n",
    "\n",
    "## Computing the 10-fold cross-validation score.\n",
    "cvScore = cross_val_score(Classifier, XTrain, YTrain['HOME_TEAM_WINS'], cv = 10)\n",
    "crossValidationScores.append(np.mean(cvScore))\n",
    "print (\"Cross Validation Score : \", np.mean(crossValidationScores))\n",
    "\n",
    "## Computing the Training and Testing Accuracies .\n",
    "Classifier.fit(XTrain,YTrain)\n",
    "print (\"Training Accuracy : \", Classifier.score(XTrain, YTrain))\n",
    "print (\"Testing Accuracy : \", Classifier.score(XTest, YTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtaining our predictions made by the best Gaussian Naive Bayes Classifier .\n",
    "YPred = Classifier.predict(XTest)\n",
    "\n",
    "## Defining the target classes .\n",
    "classLabels = ['1','0']\n",
    "\n",
    "## Obtaining the confusion matrix for our predictions .\n",
    "confusionMatrix = confusion_matrix(y_true = YTest['HOME_TEAM_WINS'], y_pred= YPred, labels=classLabels)\n",
    "confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.86      0.85      2301\n",
      "           0       0.82      0.80      0.81      1857\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      4158\n",
      "   macro avg       0.83      0.83      0.83      4158\n",
      "weighted avg       0.83      0.83      0.83      4158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Obtaining a more readable format of our Confusion Matrix in terms of a Classification Report . \n",
    "\n",
    "classificationReport = classification_report(y_true=YTest, y_pred= YPred, labels= classLabels)\n",
    "print (classificationReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualising a comparison between the true and predicted class results.\n",
    "## Defining the Final Result labels .\n",
    "resultsLabels = ['1','0']\n",
    "\n",
    "## Defining the True Labels .\n",
    "trueValues = list(list(np.unique(YTest['HOME_TEAM_WINS'] , return_counts = True))[1])\n",
    "\n",
    "## Computing Predictions with our fine-tuned Naive Bayes Classifier .\n",
    "YPred = Classifier.predict(XTest)\n",
    "predValues = list(list(np.unique(YPred , return_counts = True))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig = plt.figure()\\nax = fig.add_subplot(111)\\nind = np.arange(3)\\nwidth = 0.15      \\nrects1 = ax.bar(ind, trueValues, width, color = '#1565C0', error_kw = dict(elinewidth = 2, ecolor = 'blue'))\\n\\nrects2 = ax.bar(ind + width, predValues, width, color = '#00E676', error_kw = dict(elinewidth = 2, ecolor = 'black'))\\n\\nax.set_xlim(-width,len(ind) + width)\\nax.set_ylim(0, 450)\\nax.set_ylabel('Frequency of Result Type')\\nax.set_title('Comparison between True and Predicted Results by Result Class (Naive Bayes Set B)')\\nxTickMarks = resultsLabels\\nax.set_xticks(ind + width)\\nxtickNames = ax.set_xticklabels(xTickMarks)\\nplt.setp(xtickNames, rotation=45, fontsize=8)\\nax.legend( (rects1[0], rects2[0]), ('True', 'Predicted') )\\nplt.show()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ind = np.arange(3)\n",
    "width = 0.15      \n",
    "rects1 = ax.bar(ind, trueValues, width, color = '#1565C0', error_kw = dict(elinewidth = 2, ecolor = 'blue'))\n",
    "\n",
    "rects2 = ax.bar(ind + width, predValues, width, color = '#00E676', error_kw = dict(elinewidth = 2, ecolor = 'black'))\n",
    "\n",
    "ax.set_xlim(-width,len(ind) + width)\n",
    "ax.set_ylim(0, 450)\n",
    "ax.set_ylabel('Frequency of Result Type')\n",
    "ax.set_title('Comparison between True and Predicted Results by Result Class (Naive Bayes Set B)')\n",
    "xTickMarks = resultsLabels\n",
    "ax.set_xticks(ind + width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=45, fontsize=8)\n",
    "ax.legend( (rects1[0], rects2[0]), ('True', 'Predicted') )\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
